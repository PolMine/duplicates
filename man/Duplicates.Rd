% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Duplicates.R
\name{Duplicates}
\alias{Duplicates}
\title{Detect Duplicates}
\description{
Detect Duplicates

Detect Duplicates
}
\details{
Class for duplicate detection.

The class implements a procedure described by Fritz Kliche, Andre Blessing,
Urlich Heid and Jonathan Sonntag in the paper "The eIdentity Text
ExplorationWorkbench" presented at LREC 2014
(see \url{http://www.lrec-conf.org/proceedings/lrec2014/pdf/332_Paper.pdf}).

To detect duplicates, choices are made as follows:
\itemize{
\item If two similar articles have been published on the same day, the shorter
article will be considered the duplicate;
\item if two similar articles were published on different days, the article that
appeared later will be considered the duplicate.
}

Different \code{partition_bundle}-objects can be passed into the
\verb{$detect()}-method successively. The field \code{duplicates} will be
appended by the duplicates that are newly detected.
}
\examples{
library(polmineR)

if ("RP" \%in\% corpus()$corpus){
  D <- Duplicates$new(
    corpus = "RP",
    char_regex = "[a-zA-ZäöüÄÖÜ]",
    p_attribute = "word",
    s_attribute = "article_date",
    date_preprocessor = NULL,
    sample = 50L,
    n = 0L,
    threshold = 0.6 # default is 0.9
  )
  
  dates <- seq.Date(from = as.Date("2014-01-02"), to = as.Date("2014-02-08"), by = 1L)
  dates <- as.character(dates) \%>\% 
    intersect(s_attributes(corpus("RP"), "article_date")) \%>\% 
    as.Date()

  article_bundle <- corpus("RP") |>
    subset(article_date \%in\% as.character(dates)) |> 
    split(s_attribute = "article_id")

  D$detect(
    x = article_bundle,
    mc = 6L,
    progress = FALSE,
    f = lubridate::floor_date(
      as.Date(unlist(s_attributes(article_bundle, "article_date"))),
      unit = "month",
      week_start = 1L
    )
  )
  
  # To inspect result
  D$duplicates
  
  if (interactive()){
    for (i in 1L:nrow(D$duplicates)){
    
      print(i)
      
      corpus("NADIRASZ") \%>\%
        subset(article_id == !!D$duplicates[i][["name"]]) \%>\%
        read() \%>\%
        show()
        
      readline()
  
      corpus("NADIRASZ") \%>\%
        subset(article_id == !!D$duplicates[i][["duplicate_name"]]) \%>\%
        read() \%>\%
        show()
        
      readline()
    }
  }
}
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{corpus}}{ID of the CWB corpus (derived from \code{partition_bundle}).}

\item{\code{char_regex}}{Regular expression defining the characters to keep.}

\item{\code{char_count}}{Count of the characters in the \code{partition_bundle}.}

\item{\code{n}}{Number of days before and after a document was published.}

\item{\code{p_attribute}}{the p-attribute used (defaults to "word")}

\item{\code{s_attribute}}{the s-attribute of the date of a text in the corpus}

\item{\code{sample}}{size of the sample of the \code{partition_bundle} that the character count is based on}

\item{\code{threshold}}{Minimum similarity value to consider two texts as
duplicates.}

\item{\code{duplicates}}{A \code{data.table} with documents considered as duplicates.}

\item{\code{similarities}}{A \code{simple_triplet_matrix} with similarities of texts}

\item{\code{date_preprocessor}}{function to rework dates if not in the DD-MM-YYYY standard format}

\item{\code{annotation}}{A \code{data.table} with corpus positions and annotation data.}

\item{\code{vocabulary}}{A purged version of the vocabulary.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-Duplicates-new}{\code{Duplicates$new()}}
\item \href{#method-Duplicates-count_characters}{\code{Duplicates$count_characters()}}
\item \href{#method-Duplicates-minimize_vocabulary}{\code{Duplicates$minimize_vocabulary()}}
\item \href{#method-Duplicates-detect}{\code{Duplicates$detect()}}
\item \href{#method-Duplicates-get_duplicates_groups}{\code{Duplicates$get_duplicates_groups()}}
\item \href{#method-Duplicates-make_annotation_data}{\code{Duplicates$make_annotation_data()}}
\item \href{#method-Duplicates-encode}{\code{Duplicates$encode()}}
\item \href{#method-Duplicates-clone}{\code{Duplicates$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Duplicates-new"></a>}}
\if{latex}{\out{\hypertarget{method-Duplicates-new}{}}}
\subsection{Method \code{new()}}{
Initialize object of class \code{Duplicates}.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Duplicates$new(
  corpus,
  char_regex = "[a-zA-Z]",
  p_attribute = "word",
  s_attribute = "text_date",
  date_preprocessor = NULL,
  sample = 1000L,
  n = 1L,
  threshold = 0.9
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{corpus}}{ID of the CWB corpus that will be explored.}

\item{\code{char_regex}}{a regex defining the characters to keep}

\item{\code{p_attribute}}{The p-attribute to evaluate.}

\item{\code{s_attribute}}{the s-attribute providing the date}

\item{\code{date_preprocessor}}{A function used to preprocess dates as extracted
from \code{s_attribute}.}

\item{\code{sample}}{number of documents to define a subset of \code{partition_bundle} to
speed up character count}

\item{\code{n}}{number of days before and after a document was published}

\item{\code{threshold}}{numeric (0 < x < 1), the minimum similarity to qualify two
documents as duplicates}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Duplicates-count_characters"></a>}}
\if{latex}{\out{\hypertarget{method-Duplicates-count_characters}{}}}
\subsection{Method \code{count_characters()}}{
Count characters, required step for \verb{$detect()}.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Duplicates$count_characters(verbose = TRUE, sample = 1000)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{verbose}}{logical, whether to be verbose}

\item{\code{sample}}{number of documents to define a subset of \code{partition_bundle} to
speed up character count}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Duplicates-minimize_vocabulary"></a>}}
\if{latex}{\out{\hypertarget{method-Duplicates-minimize_vocabulary}{}}}
\subsection{Method \code{minimize_vocabulary()}}{
Reduce vocabulary
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Duplicates$minimize_vocabulary(character_selection = 1:12, verbose = TRUE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{character_selection}}{Which characters to pick.}

\item{\code{verbose}}{A \code{logical} value.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Duplicates-detect"></a>}}
\if{latex}{\out{\hypertarget{method-Duplicates-detect}{}}}
\subsection{Method \code{detect()}}{
Wrapper that implements the entire workflow for duplicate detection.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Duplicates$detect(
  x,
  n = 5L,
  f = NULL,
  character_selection = 1:12,
  min_shingle_length = n,
  verbose = TRUE,
  mc = FALSE,
  progress = TRUE
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{A \code{partition_bundle} or \code{subcorpus_bundle} object.}

\item{\code{n}}{The number of characters to use for shingling (\code{integer} value),
passed as argument \code{n} into \code{polmineR::ngrams()}. Defaults to 5, in
line with Kliche et al. 2014: 695.}

\item{\code{f}}{If n == 0, f will be passed into \code{split()} on vector with dates.
If \code{NULL} (default), the dates vector will be split by dates.}

\item{\code{character_selection}}{Numeric/integer vector used for indexing
\verb{$char_count} to select the characters to keep. Defaults to 1:12, in
line with Kliche et al. 2014: 695.}

\item{\code{min_shingle_length}}{An \code{integer} value with minimum length of
shingles that enter calculation of document similarity. Defaults to
\code{n}.}

\item{\code{verbose}}{logical, whether to be verbose}

\item{\code{mc}}{logical, whether to use multicore}

\item{\code{progress}}{logical, whether to show progress bar}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
The updated content of slot \verb{$duplicates} is returned invisibly.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Duplicates-get_duplicates_groups"></a>}}
\if{latex}{\out{\hypertarget{method-Duplicates-get_duplicates_groups}{}}}
\subsection{Method \code{get_duplicates_groups()}}{
Prepare \code{data.table} with document ids, sizes, and group.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Duplicates$get_duplicates_groups()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Duplicates-make_annotation_data"></a>}}
\if{latex}{\out{\hypertarget{method-Duplicates-make_annotation_data}{}}}
\subsection{Method \code{make_annotation_data()}}{
Turn \code{data.table} with duplicates into file with corpus positions and
annotation of duplicates.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Duplicates$make_annotation_data(
  s_attribute,
  drop = NULL,
  cols = c("size", "name"),
  order = c(1L, 1L)
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{s_attribute}}{the s-attribute providing the date}

\item{\code{drop}}{A character vector of document IDs that will be removed from
the annotation data. Useful for removing known noise that will be
excluded from the analysis otherwise.}

\item{\code{cols}}{XXX.}

\item{\code{order}}{XXX.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Duplicates-encode"></a>}}
\if{latex}{\out{\hypertarget{method-Duplicates-encode}{}}}
\subsection{Method \code{encode()}}{
Add structural attributes to CWB corpus based on the annotation data that
has been generated (data.table in field annotation).
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Duplicates$encode(method = "R")}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{method}}{XXX.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Duplicates-clone"></a>}}
\if{latex}{\out{\hypertarget{method-Duplicates-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Duplicates$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
